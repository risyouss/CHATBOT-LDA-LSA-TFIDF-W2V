{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pyLDAvis.gensim\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df=pd.read_csv('sample.csv')\n",
    "\n",
    "#preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join request and response into the same row: 'text_x' is the response from customer services; 'text_y' is the request\n",
    "def pre(df,author):\n",
    "    a=df[df.author_id==author]\n",
    "    a=a.merge(df.loc[:,['tweet_id','text']],left_on='in_response_to_tweet_id',right_on='tweet_id')\n",
    "    a=a[a.response_tweet_id.isnull()]    \n",
    "    a['text_x']=a.text_x.apply(lambda x: x[:x.find('@')]+x[x.find('@')+8:])    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    tweet_id_x     author_id  inbound                      created_at  \\\n",
       " 0       119248  AppleSupport    False  Wed Oct 11 13:38:29 +0000 2017   \n",
       " 1       119252  AppleSupport    False  Wed Oct 11 13:40:27 +0000 2017   \n",
       " 2       119262  AppleSupport    False  Wed Oct 11 13:30:39 +0000 2017   \n",
       " 3       119267  AppleSupport    False  Wed Oct 11 13:30:38 +0000 2017   \n",
       " 4       119269  AppleSupport    False  Wed Oct 11 13:30:12 +0000 2017   \n",
       " 6       119279  AppleSupport    False  Wed Oct 11 13:35:01 +0000 2017   \n",
       " 8       119293  AppleSupport    False  Wed Oct 11 13:30:00 +0000 2017   \n",
       " 9       119298  AppleSupport    False  Wed Oct 11 13:34:00 +0000 2017   \n",
       " 10      119300  AppleSupport    False  Wed Oct 11 13:31:27 +0000 2017   \n",
       " 11      119323  AppleSupport    False  Wed Oct 11 13:55:31 +0000 2017   \n",
       " \n",
       "                                                text_x response_tweet_id  \\\n",
       " 0   We can help. Which version of iOS are you on? ...               NaN   \n",
       " 1   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 2   We'd love to help! Please DM us and let us kno...               NaN   \n",
       " 3   Battery life is important, and we're here for ...               NaN   \n",
       " 4   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 6   We'd like to help. What happens when you try t...               NaN   \n",
       " 8   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 9   We'd like to provide some assistance with this...               NaN   \n",
       " 10  Are you experiencing an issue with your device...               NaN   \n",
       " 11  Is there a particular app that seems to cause ...               NaN   \n",
       " \n",
       "     in_response_to_tweet_id  tweet_id_y  \\\n",
       " 0                  119249.0      119249   \n",
       " 1                  119253.0      119253   \n",
       " 2                  119263.0      119263   \n",
       " 3                  119268.0      119268   \n",
       " 4                  119270.0      119270   \n",
       " 6                  119280.0      119280   \n",
       " 8                  119294.0      119294   \n",
       " 9                  119299.0      119299   \n",
       " 10                 119301.0      119301   \n",
       " 11                 119324.0      119324   \n",
       " \n",
       "                                                text_y  \n",
       " 0   @105838 @AppleSupport Me too am suffering , ho...  \n",
       " 1   I just updated my phone and suddenly everythin...  \n",
       " 2   @AppleSupport after the 11.0.2 my phone just s...  \n",
       " 3   Okay @76099 I used my fucking phone for 2 minu...  \n",
       " 4   @AppleSupport Can you get my iPhone 7plus back...  \n",
       " 6   So the new @76099 update does not let me liste...  \n",
       " 8   Took my phone off charge at 7:20am.\\n\\n8:03am ...  \n",
       " 9   @AppleSupport I need a new code for my I-store...  \n",
       " 10  @76099 @AppleSupport fix this update. It’s hor...  \n",
       " 11  @AppleSupport I have the latest version iOS. I...  ]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = []\n",
    "amazon.append(pre(df,'AppleSupport'))\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@105838 @AppleSupport Me too am suffering , hope the can find a solution',\n",
       " 'I just updated my phone and suddenly everything takes ages to load wtf @76099 this update sux I hate it fix it bye',\n",
       " '@AppleSupport after the 11.0.2 my phone just sucks most of the apps are broken, wifi disconnects frequently #apple #ios1102 #painfulupdate',\n",
       " 'Okay @76099 I used my fucking phone for 2 minutes and it drains it down 8 fucking percent',\n",
       " '@AppleSupport Can you get my iPhone 7plus back on the old iOS please?  Battery runs out in half the time, apps now frequently crash.',\n",
       " 'So the new @76099 update does not let me listen to music and go on whatsapp at the same time?!?',\n",
       " 'Took my phone off charge at 7:20am.\\n\\n8:03am - 60% battery remaining.\\n\\n@76099 plz I beg you, sort your battery life out😩',\n",
       " '@AppleSupport I need a new code for my I-store. I haven’t recd any but msg is too many sent. Help!',\n",
       " '@76099 @AppleSupport fix this update. It’s horrible',\n",
       " '@AppleSupport I have the latest version iOS. It started immediately after I updated my phone.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append all the questions about amazon to a list\n",
    "q = amazon[-1]['text_y'].to_list()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['105838 AppleSupport Me too am suffering  hope the can find a solution',\n",
       " 'I just updated my phone and suddenly everything takes ages to load wtf 76099 this update sux I hate it fix it bye',\n",
       " 'AppleSupport after the 1102 my phone just sucks most of the apps are broken wifi disconnects frequently apple ios1102 painfulupdate',\n",
       " 'Okay 76099 I used my fucking phone for 2 minutes and it drains it down 8 fucking percent',\n",
       " 'AppleSupport Can you get my iPhone 7plus back on the old iOS please  Battery runs out in half the time apps now frequently crash',\n",
       " 'So the new 76099 update does not let me listen to music and go on whatsapp at the same time',\n",
       " 'Took my phone off charge at 720am\\n\\n803am  60 battery remaining\\n\\n76099 plz I beg you sort your battery life out😩',\n",
       " 'AppleSupport I need a new code for my Istore I haven’t recd any but msg is too many sent Help',\n",
       " '76099 AppleSupport fix this update It’s horrible',\n",
       " 'AppleSupport I have the latest version iOS It started immediately after I updated my phone']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove '\\r' and punctuations \n",
    "new_text = []\n",
    "for tweet in q: \n",
    "    for i in tweet:\n",
    "        if i in string.punctuation or i == '@':\n",
    "            tweet = tweet.replace(i,'') #replace punctuation with nothing\n",
    "        if i == '\\r':\n",
    "            tweet = tweet.replace(i,' ') #replace \\r with space\n",
    "    new_text.append(tweet) \n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['applesupport', 'suffering', 'hope', 'find', 'solution'],\n",
       " ['updated',\n",
       "  'phone',\n",
       "  'suddenly',\n",
       "  'takes',\n",
       "  'ages',\n",
       "  'load',\n",
       "  'wtf',\n",
       "  'update',\n",
       "  'sux',\n",
       "  'hate',\n",
       "  'fix',\n",
       "  'bye'],\n",
       " ['applesupport',\n",
       "  'phone',\n",
       "  'sucks',\n",
       "  'apps',\n",
       "  'broken',\n",
       "  'wifi',\n",
       "  'disconnects',\n",
       "  'frequently',\n",
       "  'apple',\n",
       "  'painfulupdate'],\n",
       " ['fucking', 'phone', 'minutes', 'drains', 'fucking', 'percent'],\n",
       " ['applesupport',\n",
       "  'iphone',\n",
       "  'back',\n",
       "  'ios',\n",
       "  'battery',\n",
       "  'runs',\n",
       "  'half',\n",
       "  'time',\n",
       "  'apps',\n",
       "  'frequently',\n",
       "  'crash'],\n",
       " ['update', 'listen', 'music', 'whatsapp', 'time'],\n",
       " ['phone', 'charge', 'battery', 'plz', 'beg', 'sort', 'battery', 'life'],\n",
       " ['applesupport', 'code', 'istore', 'recd', 'msg'],\n",
       " ['applesupport', 'fix', 'update', 'horrible'],\n",
       " ['applesupport',\n",
       "  'latest',\n",
       "  'version',\n",
       "  'ios',\n",
       "  'started',\n",
       "  'immediately',\n",
       "  'updated',\n",
       "  'phone']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words, to lowercase and tokenize\n",
    "mystopwords = stopwords.words()\n",
    "tokens_list = [[word for word in tweet.lower().split(' ') if word not in mystopwords and word.isalpha() and word != 'amazon' and word != 'amazonhelp']\n",
    "         for tweet in new_text]\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['applesupport'],\n",
       " ['updated', 'phone', 'update', 'fix'],\n",
       " ['applesupport', 'phone', 'apps', 'frequently'],\n",
       " ['fucking', 'phone', 'fucking'],\n",
       " ['applesupport', 'ios', 'battery', 'time', 'apps', 'frequently'],\n",
       " ['update', 'time'],\n",
       " ['phone', 'battery', 'battery'],\n",
       " ['applesupport'],\n",
       " ['applesupport', 'fix', 'update'],\n",
       " ['applesupport', 'ios', 'updated', 'phone']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "for tokens in tokens_list:\n",
    "    for token in tokens:\n",
    "        frequency[token] += 1      \n",
    "tokens_list = [[token for token in tokens if frequency[token]>1]\n",
    "              for tokens in tokens_list]\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7f69c103fdf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Term Document Matrix\n",
    "# generate token dictionary class\n",
    "dictionary = corpora.Dictionary(tokens_list) \n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1)],\n",
       " [(1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(0, 1), (2, 1), (5, 1), (6, 1)],\n",
       " [(2, 1), (7, 2)],\n",
       " [(0, 1), (5, 1), (6, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(3, 1), (10, 1)],\n",
       " [(2, 1), (8, 2)],\n",
       " [(0, 1)],\n",
       " [(0, 1), (1, 1), (3, 1)],\n",
       " [(0, 1), (2, 1), (4, 1), (9, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a unique token list \n",
    "sort_token = sorted(dictionary.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token = [token for (ID,token) in sort_token]\n",
    "\n",
    "# build a corpus\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applesupport</th>\n",
       "      <th>fix</th>\n",
       "      <th>phone</th>\n",
       "      <th>update</th>\n",
       "      <th>updated</th>\n",
       "      <th>apps</th>\n",
       "      <th>frequently</th>\n",
       "      <th>fucking</th>\n",
       "      <th>battery</th>\n",
       "      <th>ios</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   applesupport  fix  phone  update  updated  apps  frequently  fucking  \\\n",
       "0             1    0      0       0        0     0           0        0   \n",
       "1             0    1      1       1        1     0           0        0   \n",
       "2             1    0      1       0        0     1           1        0   \n",
       "3             0    0      1       0        0     0           0        2   \n",
       "4             1    0      0       0        0     1           1        0   \n",
       "5             0    0      0       1        0     0           0        0   \n",
       "6             0    0      1       0        0     0           0        0   \n",
       "7             1    0      0       0        0     0           0        0   \n",
       "8             1    1      0       1        0     0           0        0   \n",
       "9             1    0      1       0        1     0           0        0   \n",
       "\n",
       "   battery  ios  time  \n",
       "0        0    0     0  \n",
       "1        0    0     0  \n",
       "2        0    0     0  \n",
       "3        0    0     0  \n",
       "4        1    1     1  \n",
       "5        0    0     1  \n",
       "6        2    0     0  \n",
       "7        0    0     0  \n",
       "8        0    0     0  \n",
       "9        0    1     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a Term Document Matrix\n",
    "matrix = gensim.matutils.corpus2dense(corpus,num_terms=len(dictionary),dtype = 'int')\n",
    "matrix = matrix.T \n",
    "#transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas dataframe\n",
    "matrix_df = pd.DataFrame(matrix, columns=unique_token)\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.091*\"applesupport\" + 0.091*\"phone\" + 0.091*\"update\" + 0.091*\"battery\" + 0.091*\"time\" + 0.091*\"fucking\" + 0.091*\"updated\" + 0.091*\"frequently\" + 0.091*\"apps\" + 0.091*\"fix\"'),\n",
       " (1,\n",
       "  '0.155*\"applesupport\" + 0.155*\"battery\" + 0.155*\"time\" + 0.155*\"frequently\" + 0.155*\"apps\" + 0.155*\"ios\" + 0.014*\"phone\" + 0.014*\"update\" + 0.014*\"fucking\" + 0.014*\"fix\"'),\n",
       " (2,\n",
       "  '0.524*\"applesupport\" + 0.048*\"phone\" + 0.048*\"update\" + 0.048*\"battery\" + 0.048*\"fucking\" + 0.048*\"time\" + 0.048*\"fix\" + 0.048*\"updated\" + 0.048*\"apps\" + 0.048*\"frequently\"'),\n",
       " (3,\n",
       "  '0.412*\"fucking\" + 0.216*\"phone\" + 0.216*\"applesupport\" + 0.020*\"update\" + 0.020*\"battery\" + 0.020*\"fix\" + 0.020*\"apps\" + 0.020*\"ios\" + 0.020*\"updated\" + 0.020*\"time\"'),\n",
       " (4,\n",
       "  '0.091*\"applesupport\" + 0.091*\"phone\" + 0.091*\"update\" + 0.091*\"fix\" + 0.091*\"fucking\" + 0.091*\"time\" + 0.091*\"frequently\" + 0.091*\"battery\" + 0.091*\"ios\" + 0.091*\"apps\"'),\n",
       " (5,\n",
       "  '0.296*\"update\" + 0.155*\"phone\" + 0.155*\"fix\" + 0.155*\"updated\" + 0.155*\"time\" + 0.014*\"applesupport\" + 0.014*\"battery\" + 0.014*\"fucking\" + 0.014*\"apps\" + 0.014*\"ios\"'),\n",
       " (6,\n",
       "  '0.256*\"phone\" + 0.174*\"applesupport\" + 0.174*\"battery\" + 0.091*\"ios\" + 0.091*\"updated\" + 0.091*\"frequently\" + 0.091*\"apps\" + 0.008*\"update\" + 0.008*\"fucking\" + 0.008*\"time\"'),\n",
       " (7,\n",
       "  '0.091*\"applesupport\" + 0.091*\"update\" + 0.091*\"phone\" + 0.091*\"time\" + 0.091*\"battery\" + 0.091*\"fucking\" + 0.091*\"updated\" + 0.091*\"fix\" + 0.091*\"ios\" + 0.091*\"apps\"'),\n",
       " (8,\n",
       "  '0.268*\"applesupport\" + 0.268*\"update\" + 0.268*\"fix\" + 0.024*\"phone\" + 0.024*\"battery\" + 0.024*\"fucking\" + 0.024*\"time\" + 0.024*\"apps\" + 0.024*\"frequently\" + 0.024*\"updated\"'),\n",
       " (9,\n",
       "  '0.091*\"applesupport\" + 0.091*\"update\" + 0.091*\"phone\" + 0.091*\"battery\" + 0.091*\"time\" + 0.091*\"fucking\" + 0.091*\"fix\" + 0.091*\"ios\" + 0.091*\"updated\" + 0.091*\"frequently\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit to LDA model\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=10) \n",
    "\n",
    "#Topic matrix (V matrix)\n",
    "lda.print_topics(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.549968</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.819988</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.819982</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.774993</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025005</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.871419</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.699988</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.774993</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.549968</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.774982</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.819982</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.050000  0.050006  0.549968  0.050008  0.050000  0.050000  0.050008   \n",
       "1  0.020000  0.020000  0.020000  0.020002  0.020000  0.819988  0.020005   \n",
       "2  0.020000  0.020007  0.020005  0.020003  0.020000  0.020001  0.819982   \n",
       "3  0.025000  0.025000  0.025000  0.774993  0.025000  0.025002  0.025005   \n",
       "4  0.014286  0.871419  0.014289  0.014287  0.014286  0.014286  0.014289   \n",
       "5  0.033333  0.033341  0.033333  0.033333  0.033333  0.699988  0.033333   \n",
       "6  0.025000  0.025004  0.025000  0.025002  0.025000  0.025001  0.774993   \n",
       "7  0.050000  0.050006  0.549968  0.050008  0.050000  0.050000  0.050008   \n",
       "8  0.025000  0.025002  0.025006  0.025002  0.025000  0.025006  0.025002   \n",
       "9  0.020000  0.020004  0.020005  0.020003  0.020000  0.020004  0.819982   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.050000  0.050010  0.050000  \n",
       "1  0.020000  0.020005  0.020000  \n",
       "2  0.020000  0.020002  0.020000  \n",
       "3  0.025000  0.025000  0.025000  \n",
       "4  0.014286  0.014287  0.014286  \n",
       "5  0.033333  0.033338  0.033333  \n",
       "6  0.025000  0.025000  0.025000  \n",
       "7  0.050000  0.050010  0.050000  \n",
       "8  0.025000  0.774982  0.025000  \n",
       "9  0.020000  0.020002  0.020000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate U Matrix for LDA model\n",
    "corpus_lda = lda[corpus] \n",
    "#transform lda model\n",
    "\n",
    "#convert corpus_lda to numpy matrix\n",
    "U_matrix_lda = gensim.matutils.corpus2dense(corpus_lda,num_terms=10).T\n",
    "\n",
    "#write U_matrix into pandas dataframe and output\n",
    "U_matrix_lda_df = pd.DataFrame(U_matrix_lda)\n",
    "U_matrix_lda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "print (matrix_df.shape)\n",
    "print (U_matrix_lda_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el484651400921857037284848406646\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el484651400921857037284848406646_data = {\"mdsDat\": {\"x\": [-0.1143700082960859, -0.12912229809066808, 0.1997964325913629, -0.05584500802795806, 0.12075652668027252, -0.050440928289227395, 0.007303703509836882, 0.00730895548943456, 0.007306433842488416, 0.007306190590543859], \"y\": [-0.014578221174697691, -0.12342275298133876, -0.03164701264777495, 0.18632771044329463, 0.013202931443775387, 0.03898914576924105, -0.017211762529928575, -0.017221792318412768, -0.01721718150627315, -0.017221064497885363], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [30.217065689098117, 18.904090165018943, 16.937725678964945, 9.57234732512419, 9.572262406532426, 5.539971033182608, 2.3141344255196925, 2.3141344255196925, 2.3141344255196925, 2.3141344255196925]}, \"tinfo\": {\"Term\": [\"applesupport\", \"update\", \"fucking\", \"fix\", \"phone\", \"battery\", \"time\", \"frequently\", \"ios\", \"apps\", \"updated\", \"phone\", \"battery\", \"updated\", \"ios\", \"frequently\", \"apps\", \"applesupport\", \"fucking\", \"fix\", \"time\", \"update\", \"time\", \"frequently\", \"apps\", \"ios\", \"battery\", \"applesupport\", \"fucking\", \"fix\", \"updated\", \"update\", \"phone\", \"update\", \"fix\", \"updated\", \"time\", \"phone\", \"fucking\", \"apps\", \"ios\", \"frequently\", \"battery\", \"applesupport\", \"fucking\", \"phone\", \"applesupport\", \"fix\", \"updated\", \"time\", \"apps\", \"ios\", \"frequently\", \"update\", \"battery\", \"fix\", \"update\", \"applesupport\", \"fucking\", \"updated\", \"time\", \"apps\", \"frequently\", \"ios\", \"battery\", \"phone\", \"applesupport\", \"fucking\", \"fix\", \"updated\", \"time\", \"apps\", \"frequently\", \"ios\", \"update\", \"battery\", \"phone\", \"fucking\", \"fix\", \"updated\", \"time\", \"frequently\", \"apps\", \"ios\", \"update\", \"battery\", \"phone\", \"applesupport\", \"fucking\", \"fix\", \"updated\", \"time\", \"frequently\", \"ios\", \"apps\", \"update\", \"battery\", \"phone\", \"applesupport\", \"fucking\", \"fix\", \"updated\", \"time\", \"ios\", \"apps\", \"frequently\", \"update\", \"battery\", \"phone\", \"applesupport\", \"fucking\", \"fix\", \"updated\", \"time\", \"ios\", \"frequently\", \"apps\", \"update\", \"battery\", \"phone\", \"applesupport\"], \"Freq\": [5.0, 2.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.3998558691934084, 1.6256600009120223, 0.8515711233880092, 0.8515761483942264, 0.8515601660827857, 0.8515486504435381, 1.62578283439733, 0.07743565986885813, 0.07743059996676449, 0.07743281585492273, 0.07743633161448091, 0.9079104323287251, 0.9078985561560796, 0.9078975955832922, 0.9078774235547545, 0.9079192521334105, 0.9079666694991937, 0.08255957737277633, 0.08255119419208537, 0.08254960597230603, 0.08256557549489832, 0.08257242503380922, 1.5529352700406296, 0.8134791285799414, 0.8134770160607019, 0.8134236553895402, 0.8135015838770432, 0.07397173896733111, 0.07397045776353306, 0.07396598822051237, 0.07396580728715157, 0.07397714251770077, 0.07402714369646068, 1.2218555760377927, 0.6400431199100709, 0.639926516730781, 0.05820040200729165, 0.05819730121171042, 0.05819677612154961, 0.058198390082886006, 0.058197334375299524, 0.058194841578851866, 0.058213534788576854, 0.05820370731167235, 0.7960689757381584, 0.7960873703123973, 0.7961310574262147, 0.07238982395624653, 0.07238432437650863, 0.07238717089265438, 0.07238542429245622, 0.07238443492082497, 0.07238373296441622, 0.07239751231344796, 0.07240119896639788, 0.8993701546061429, 0.08180318222918438, 0.08180184509311939, 0.08179790406050674, 0.08180268960010781, 0.08179595273754106, 0.08179322088538912, 0.08179291379193879, 0.0818086587290487, 0.08180538306557845, 0.08181920866862377, 0.06520854407503329, 0.06520334882245865, 0.0652067855996248, 0.06520986961272723, 0.06520544402720069, 0.06520402228112573, 0.06520288916019382, 0.0652206289166704, 0.06521182050489775, 0.06522724591531999, 0.06528107450449613, 0.06521267034559669, 0.06521272913960731, 0.06520793475528688, 0.06521142498155359, 0.065210227721701, 0.06520859752413385, 0.0652082982091707, 0.06521836801971662, 0.06520911598040931, 0.06522952284700394, 0.06525281596502892, 0.06521113635641056, 0.0652077744079852, 0.06520779578762542, 0.06521279862343804, 0.06520736819482092, 0.06520564178887277, 0.0652025363961301, 0.06522135582443804, 0.06521218395878157, 0.06521840008917695, 0.06527461785314823, 0.0652108263516273, 0.06520951684866352, 0.06520741095410137, 0.06521319949169226, 0.06520768354451424, 0.06520706887985778, 0.06520667335651362, 0.0652195171753787, 0.06521326897552299, 0.06521753421374785, 0.06526893086884841], \"Total\": [5.0, 2.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.351086108714603, 3.0808093876734444, 2.220807202166382, 2.3066200797248104, 2.3066223039359723, 2.30662110653893, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.2720008328969112, 2.909926610916236, 2.2720008328969112, 2.3066223039359723, 2.30662110653893, 2.3066200797248104, 3.0808093876734444, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.909926610916236, 4.351086108714603, 2.909926610916236, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 4.351086108714603, 1.8708587355608572, 2.30662110653893, 2.3066200797248104, 2.3066223039359723, 3.0808093876734444, 5.204281815547645, 1.8708587355608572, 4.351086108714603, 5.204281815547645, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.30662110653893, 2.3066200797248104, 2.3066223039359723, 2.909926610916236, 3.0808093876734444, 2.170365514796076, 2.909926610916236, 5.204281815547645, 1.8708587355608572, 2.220807202166382, 2.2720008328969112, 2.30662110653893, 2.3066223039359723, 2.3066200797248104, 3.0808093876734444, 4.351086108714603, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.30662110653893, 2.3066223039359723, 2.3066200797248104, 2.909926610916236, 3.0808093876734444, 4.351086108714603, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.3066223039359723, 2.30662110653893, 2.3066200797248104, 2.909926610916236, 3.0808093876734444, 4.351086108714603, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.3066223039359723, 2.3066200797248104, 2.30662110653893, 2.909926610916236, 3.0808093876734444, 4.351086108714603, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.3066200797248104, 2.30662110653893, 2.3066223039359723, 2.909926610916236, 3.0808093876734444, 4.351086108714603, 5.204281815547645, 1.8708587355608572, 2.170365514796076, 2.220807202166382, 2.2720008328969112, 2.3066200797248104, 2.3066223039359723, 2.30662110653893, 2.909926610916236, 3.0808093876734444, 4.351086108714603, 5.204281815547645], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.3618, -1.7513, -2.3979, -2.3979, -2.3979, -2.3979, -1.7512, -4.7955, -4.7956, -4.7956, -4.7955, -1.8648, -1.8648, -1.8648, -1.8648, -1.8648, -1.8647, -4.2624, -4.2625, -4.2626, -4.2624, -4.2623, -1.2182, -1.8648, -1.8648, -1.8649, -1.8648, -4.2624, -4.2624, -4.2625, -4.2625, -4.2624, -4.2617, -0.8873, -1.5339, -1.5341, -3.9316, -3.9316, -3.9316, -3.9316, -3.9316, -3.9317, -3.9313, -3.9315, -1.3158, -1.3157, -1.3157, -3.7134, -3.7135, -3.7134, -3.7134, -3.7135, -3.7135, -3.7133, -3.7132, -0.6469, -3.0442, -3.0443, -3.0443, -3.0443, -3.0443, -3.0444, -3.0444, -3.0442, -3.0442, -3.044, -2.398, -2.3981, -2.398, -2.398, -2.3981, -2.3981, -2.3981, -2.3978, -2.398, -2.3977, -2.3969, -2.398, -2.398, -2.398, -2.398, -2.398, -2.398, -2.398, -2.3979, -2.398, -2.3977, -2.3973, -2.398, -2.398, -2.398, -2.398, -2.398, -2.3981, -2.3981, -2.3978, -2.398, -2.3979, -2.397, -2.398, -2.398, -2.398, -2.3979, -2.398, -2.398, -2.398, -2.3978, -2.3979, -2.3979, -2.3971], \"loglift\": [11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6017, 0.5575, 0.2382, 0.2003, 0.2003, 0.2003, 0.0333, -1.9879, -2.1365, -2.1822, -2.4297, 0.7485, 0.7334, 0.7334, 0.7334, 0.444, -0.0802, -1.4548, -1.6034, -1.6264, -1.8965, -2.2987, 1.1476, 0.7943, 0.7713, 0.7485, 0.0988, -1.4548, -1.6642, -1.6643, -1.6643, -1.9536, -2.4772, 1.9203, 0.4296, 0.2504, -1.2725, -1.2955, -1.3183, -1.3334, -1.3334, -1.3335, -1.5655, -1.6227, 1.3433, 1.0501, 0.4688, -0.9058, -1.0773, -1.1001, -1.1152, -1.1152, -1.1153, -1.4045, -1.7497, 1.1376, -0.2367, -0.3852, -0.4082, -0.4309, -0.4461, -0.4462, -0.4462, -0.6783, -0.7354, -1.0805, 0.4096, 0.261, 0.2381, 0.2153, 0.2001, 0.2001, 0.2001, -0.032, -0.0892, -0.4342, -0.6124, 0.4096, 0.2611, 0.2381, 0.2154, 0.2002, 0.2002, 0.2002, -0.032, -0.0892, -0.4341, -0.6128, 0.4096, 0.2611, 0.2381, 0.2154, 0.2002, 0.2001, 0.2001, -0.032, -0.0892, -0.4343, -0.6125, 0.4096, 0.2611, 0.2381, 0.2154, 0.2002, 0.2002, 0.2002, -0.032, -0.0892, -0.4343, -0.6126]}, \"token.table\": {\"Topic\": [1, 2, 4, 5, 6, 1, 2, 1, 2, 3, 5, 1, 2, 4, 1, 2, 1, 3, 4, 2, 3, 3, 5, 1, 3], \"Freq\": [0.3842989428483785, 0.19214947142418926, 0.19214947142418926, 0.19214947142418926, 0.19214947142418926, 0.43353457451904337, 0.43353457451904337, 0.649180052489503, 0.3245900262447515, 0.46075188404104295, 0.46075188404104295, 0.4335343494657191, 0.4335343494657191, 0.5345139004844286, 0.43353476751113007, 0.43353476751113007, 0.4596553481196996, 0.2298276740598498, 0.2298276740598498, 0.4401406837183909, 0.4401406837183909, 0.6873025568745422, 0.3436512784372711, 0.45028672413548865, 0.45028672413548865], \"Term\": [\"applesupport\", \"applesupport\", \"applesupport\", \"applesupport\", \"applesupport\", \"apps\", \"apps\", \"battery\", \"battery\", \"fix\", \"fix\", \"frequently\", \"frequently\", \"fucking\", \"ios\", \"ios\", \"phone\", \"phone\", \"phone\", \"time\", \"time\", \"update\", \"update\", \"updated\", \"updated\"]}, \"R\": 11, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 2, 6, 4, 9, 3, 1, 5, 8, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el484651400921857037284848406646\", ldavis_el484651400921857037284848406646_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el484651400921857037284848406646\", ldavis_el484651400921857037284848406646_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el484651400921857037284848406646\", ldavis_el484651400921857037284848406646_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6     -0.114370 -0.014578       1        1  30.217066\n",
       "1     -0.129122 -0.123423       2        1  18.904090\n",
       "5      0.199796 -0.031647       3        1  16.937726\n",
       "3     -0.055845  0.186328       4        1   9.572347\n",
       "8      0.120757  0.013203       5        1   9.572262\n",
       "2     -0.050441  0.038989       6        1   5.539971\n",
       "0      0.007304 -0.017212       7        1   2.314134\n",
       "4      0.007309 -0.017222       8        1   2.314134\n",
       "7      0.007306 -0.017217       9        1   2.314134\n",
       "9      0.007306 -0.017221      10        1   2.314134, topic_info=            Term      Freq     Total Category  logprob  loglift\n",
       "0   applesupport  5.000000  5.000000  Default  11.0000  11.0000\n",
       "3         update  2.000000  2.000000  Default  10.0000  10.0000\n",
       "7        fucking  1.000000  1.000000  Default   9.0000   9.0000\n",
       "1            fix  2.000000  2.000000  Default   8.0000   8.0000\n",
       "2          phone  4.000000  4.000000  Default   7.0000   7.0000\n",
       "..           ...       ...       ...      ...      ...      ...\n",
       "5           apps  0.065207  2.306621  Topic10  -2.3980   0.2002\n",
       "3         update  0.065220  2.909927  Topic10  -2.3978  -0.0320\n",
       "8        battery  0.065213  3.080809  Topic10  -2.3979  -0.0892\n",
       "2          phone  0.065218  4.351086  Topic10  -2.3979  -0.4343\n",
       "0   applesupport  0.065269  5.204282  Topic10  -2.3971  -0.6126\n",
       "\n",
       "[121 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "0         1  0.384299  applesupport\n",
       "0         2  0.192149  applesupport\n",
       "0         4  0.192149  applesupport\n",
       "0         5  0.192149  applesupport\n",
       "0         6  0.192149  applesupport\n",
       "5         1  0.433535          apps\n",
       "5         2  0.433535          apps\n",
       "8         1  0.649180       battery\n",
       "8         2  0.324590       battery\n",
       "1         3  0.460752           fix\n",
       "1         5  0.460752           fix\n",
       "6         1  0.433534    frequently\n",
       "6         2  0.433534    frequently\n",
       "7         4  0.534514       fucking\n",
       "9         1  0.433535           ios\n",
       "9         2  0.433535           ios\n",
       "2         1  0.459655         phone\n",
       "2         3  0.229828         phone\n",
       "2         4  0.229828         phone\n",
       "10        2  0.440141          time\n",
       "10        3  0.440141          time\n",
       "3         3  0.687303        update\n",
       "3         5  0.343651        update\n",
       "4         1  0.450287       updated\n",
       "4         3  0.450287       updated, R=11, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 2, 6, 4, 9, 3, 1, 5, 8, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jieba in /home/risy/.local/lib/python3.10/site-packages (0.42.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import time\n",
    "import jieba\n",
    "import codecs\n",
    "import gc\n",
    "import tqdm\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pyLDAvis.gensim\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for segmentation\n",
    "class Seg(object):\n",
    "#     stopword_filepath = \"stopword.txt\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set()\n",
    "#         self.read_in_stopword()\n",
    "\n",
    "    def read_in_stopword(self):\n",
    "        file_obj = codecs.open(self.stopword_filepath, 'r', 'utf-8')\n",
    "        while True:\n",
    "            line = file_obj.readline()\n",
    "            line=line.strip('\\r\\n')\n",
    "            if not line:\n",
    "                break\n",
    "            self.stopwords.add(line)\n",
    "        file_obj.close()\n",
    "\n",
    "    #tokenize, remove stop words, and stemming using Porter Stemmer  \n",
    "    def cut(self, sentence, stopword= False, stemming = True):\n",
    "        seg_list = nltk.word_tokenize(sentence)\n",
    "        results = []\n",
    "        if stopword:\n",
    "            for seg in seg_list:\n",
    "                if seg in self.stopwords:\n",
    "                    continue\n",
    "                if seg.isalpha():\n",
    "                    results.append(seg)\n",
    "        else:\n",
    "            results=[token for token in seg_list if token.isalpha()]\n",
    "        if stemming:\n",
    "            porter = nltk.PorterStemmer()\n",
    "            results=[porter.stem(token.lower()) for token in results]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for sentences\n",
    "class Sentence(object):\n",
    "    def __init__(self, sentence, seg, id=0):\n",
    "        self.id = id\n",
    "        self.origin_sentence = sentence\n",
    "        self.cuted_sentence = self.cut(seg)\n",
    "\n",
    "    # sentence segmentation\n",
    "    def cut(self, seg):\n",
    "        return seg.cut(self.origin_sentence)\n",
    "\n",
    "    # get words after sentence segmentation\n",
    "    def get_cuted_sentence(self):\n",
    "        return self.cuted_sentence\n",
    "\n",
    "    def get_origin_sentence(self):\n",
    "        return self.origin_sentence\n",
    "\n",
    "    # set scores for sentences\n",
    "    def set_score(self, score):\n",
    "        self.score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate class for calculating similarity\n",
    "class SentenceSimilarity():\n",
    "    def __init__(self, seg, csName):\n",
    "        self.seg = seg\n",
    "        self.csName = csName.lower()\n",
    "\n",
    "    def set_sentences(self, sentences):\n",
    "        self.sentences = []\n",
    "        for i in range(0, len(sentences)):\n",
    "            self.sentences.append(Sentence(sentences[i], self.seg, i))\n",
    "\n",
    "    # get words after sentence segmentation\n",
    "    def get_cuted_sentences(self):\n",
    "        cuted_sentences = []\n",
    "        for sentence in self.sentences:\n",
    "            cuted_sentences.append(sentence.get_cuted_sentence())\n",
    "        return cuted_sentences\n",
    "\n",
    "    # using basic model to build complicated models\n",
    "    def simple_model(self, min_frequency = 1):\n",
    "        self.texts = self.get_cuted_sentences()\n",
    "\n",
    "        # remove words with lowest frequency\n",
    "        frequency = defaultdict(int)\n",
    "        for text in self.texts:\n",
    "            for token in text:\n",
    "                frequency[token] += 1        \n",
    "        self.texts = [[token for token in text if (frequency[token] > min_frequency) and (token != self.csName)] for text in self.texts]\n",
    "        # generate dictionary class\n",
    "        self.dictionary = corpora.Dictionary(self.texts)\n",
    "        # build a corpus\n",
    "        self.corpus_simple = [self.dictionary.doc2bow(text) for text in self.texts]\n",
    "    \n",
    "    def average_word_vectors(self,words, model, vocabulary, num_features):    \n",
    "        feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "        return feature_vector \n",
    "   \n",
    "    # averaged word vector features \n",
    "    def averaged_word_vectorizer(self,corpus, model, num_features):\n",
    "        vocabulary = set(model.wv.index2word)\n",
    "        if type(corpus[0])==list:\n",
    "            features = [self.average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                            for tokenized_sentence in corpus]\n",
    "        else:\n",
    "            features=self.average_word_vectors(corpus, model, vocabulary, num_features)\n",
    "        return np.array(features)\n",
    "        \n",
    "    # build word2vec model      \n",
    "    def w2vModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.Word2Vec(self.texts,size=200, min_count=5)\n",
    "        self.features = self.averaged_word_vectorizer(corpus=self.texts,\n",
    "                                                 model=self.model,\n",
    "                                                 num_features=200)           \n",
    "    # build tfidf model\n",
    "    def TfidfModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.TfidfModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for TFIDF model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # lsi model\n",
    "    def LsiModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.LsiModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for LSI model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # lda model\n",
    "    def LdaModel(self):\n",
    "        self.simple_model()\n",
    "        # switch from simple model to comprehensive\n",
    "        self.model = models.LdaModel(self.corpus_simple)\n",
    "        self.corpus = self.model[self.corpus_simple]\n",
    "        # Generate Similarity Matrix for LDA model\n",
    "        self.index = similarities.MatrixSimilarity(self.corpus)\n",
    "\n",
    "    # preliminary steps for input sentences\n",
    "    def sentence2vec(self, sentence):\n",
    "        sentence = Sentence(sentence, self.seg).get_cuted_sentence()\n",
    "        vec_bow = self.dictionary.doc2bow(sentence)\n",
    "        return self.model[vec_bow]\n",
    "    \n",
    "    def bow2vec(self):\n",
    "        vec = []\n",
    "        length = max(self.dictionary) + 1\n",
    "        for content in self.corpus:\n",
    "            sentence_vectors = np.zeros(length)\n",
    "            for co in content:\n",
    "                sentence_vectors[co[0]] = co[1]  # 将句子出现的单词的tf-idf表示放入矩阵中\n",
    "            vec.append(sentence_vectors)\n",
    "        return vec\n",
    "\n",
    "    # look for the most similar sentences\n",
    "    # input: test sentence    \n",
    "    def cosine_similarity(self,x,y):\n",
    "        num = x.dot(y.T)\n",
    "        denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "        return num / denom\n",
    "    \n",
    "    def similarity_k(self, sentence, k):        \n",
    "        sentence_vec = self.sentence2vec(sentence)\n",
    "        sims = self.index[sentence_vec]\n",
    "        sim_k = sorted(enumerate(sims), key=lambda item: item[1], reverse=True)[:k]\n",
    "        indexs = [i[0] for i in sim_k]\n",
    "        scores = [i[1] for i in sim_k]\n",
    "        return indexs, scores\n",
    "    \n",
    "    def similarity_v(self, sentence, k):       \n",
    "        cuts=Sentence(sentence, self.seg).get_cuted_sentence()\n",
    "        sentence_vec=self.averaged_word_vectorizer(corpus=cuts,\n",
    "                                      model=self.model,\n",
    "                                     num_features=200)\n",
    "        d=[]\n",
    "        for i in range(len(self.features)):\n",
    "            score=self.cosine_similarity(self.features[i],sentence_vec)\n",
    "            if score >=0 or score <=0:\n",
    "                d.append([i,score]) \n",
    "        sim_k = sorted(d, key=lambda item: item[1], reverse=True)[:k]\n",
    "        indexs = [i[0] for i in sim_k]\n",
    "        scores = [i[1] for i in sim_k]\n",
    "        return indexs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(df,seg):\n",
    "    qList = []\n",
    "    # list of keywords in tweets\n",
    "    qList_kw = []\n",
    "    aList = []\n",
    "    data = df[['text_y','text_x']]\n",
    "    data_ls = np.array(data).tolist()\n",
    "    for t in data_ls:\n",
    "        qList.append(t[0])\n",
    "        qList_kw.append(seg.cut(t[0]))\n",
    "        aList.append(t[1])\n",
    "    return qList_kw, qList, aList\n",
    "\n",
    "# define function for frequency distribution plot\n",
    "def plot_words(wordList):\n",
    "    fDist = FreqDist(wordList)\n",
    "    #print(fDist.most_common())\n",
    "    print(\"Total number of words: \",fDist.N())\n",
    "    print(\"Total number of distinct words: \",fDist.B())\n",
    "    fDist.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df=pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AppleSupport</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpotifyCares</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesco</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VirginTrains</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British_Airways</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_Spectrum</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChaseSupport</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HPSupport</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthwestAir</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  inbound  created_at  text  response_tweet_id  \\\n",
       "author_id                                                                 \n",
       "AppleSupport           13       13          13    13                  3   \n",
       "SpotifyCares            8        8           8     8                  6   \n",
       "Tesco                   8        8           8     8                  6   \n",
       "VirginTrains            4        4           4     4                  3   \n",
       "British_Airways         3        3           3     3                  1   \n",
       "Ask_Spectrum            1        1           1     1                  1   \n",
       "ChaseSupport            1        1           1     1                  0   \n",
       "HPSupport               1        1           1     1                  0   \n",
       "O2                      1        1           1     1                  0   \n",
       "SouthwestAir            1        1           1     1                  1   \n",
       "\n",
       "                 in_response_to_tweet_id  \n",
       "author_id                                 \n",
       "AppleSupport                          13  \n",
       "SpotifyCares                           8  \n",
       "Tesco                                  8  \n",
       "VirginTrains                           4  \n",
       "British_Airways                        3  \n",
       "Ask_Spectrum                           1  \n",
       "ChaseSupport                           1  \n",
       "HPSupport                              1  \n",
       "O2                                     1  \n",
       "SouthwestAir                           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort by companies responded the most\n",
    "df[df.inbound==False].groupby('author_id').count().sort_values('text',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected the three most responsive companies\n",
    "clist=df[df.inbound==False].groupby('author_id').count().sort_values('text',ascending=False)[:3].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AppleSupport', 'SpotifyCares', 'Tesco']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join request and response into the same row: 'text_x' is the response from customer services; 'text_y' is the request\n",
    "def pre(df,author):\n",
    "    a=df[df.author_id==author]\n",
    "    a=a.merge(df.loc[:,['tweet_id','text']],left_on='in_response_to_tweet_id',right_on='tweet_id')\n",
    "    a=a[a.response_tweet_id.isnull()]    \n",
    "    a['text_x']=a.text_x.apply(lambda x: x[:x.find('@')]+x[x.find('@')+8:])    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    tweet_id_x     author_id  inbound                      created_at  \\\n",
       " 0       119248  AppleSupport    False  Wed Oct 11 13:38:29 +0000 2017   \n",
       " 1       119252  AppleSupport    False  Wed Oct 11 13:40:27 +0000 2017   \n",
       " 2       119262  AppleSupport    False  Wed Oct 11 13:30:39 +0000 2017   \n",
       " 3       119267  AppleSupport    False  Wed Oct 11 13:30:38 +0000 2017   \n",
       " 4       119269  AppleSupport    False  Wed Oct 11 13:30:12 +0000 2017   \n",
       " 6       119279  AppleSupport    False  Wed Oct 11 13:35:01 +0000 2017   \n",
       " 8       119293  AppleSupport    False  Wed Oct 11 13:30:00 +0000 2017   \n",
       " 9       119298  AppleSupport    False  Wed Oct 11 13:34:00 +0000 2017   \n",
       " 10      119300  AppleSupport    False  Wed Oct 11 13:31:27 +0000 2017   \n",
       " 11      119323  AppleSupport    False  Wed Oct 11 13:55:31 +0000 2017   \n",
       " \n",
       "                                                text_x response_tweet_id  \\\n",
       " 0   We can help. Which version of iOS are you on? ...               NaN   \n",
       " 1   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 2   We'd love to help! Please DM us and let us kno...               NaN   \n",
       " 3   Battery life is important, and we're here for ...               NaN   \n",
       " 4   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 6   We'd like to help. What happens when you try t...               NaN   \n",
       " 8   Thanks for reaching out to us. We are always h...               NaN   \n",
       " 9   We'd like to provide some assistance with this...               NaN   \n",
       " 10  Are you experiencing an issue with your device...               NaN   \n",
       " 11  Is there a particular app that seems to cause ...               NaN   \n",
       " \n",
       "     in_response_to_tweet_id  tweet_id_y  \\\n",
       " 0                  119249.0      119249   \n",
       " 1                  119253.0      119253   \n",
       " 2                  119263.0      119263   \n",
       " 3                  119268.0      119268   \n",
       " 4                  119270.0      119270   \n",
       " 6                  119280.0      119280   \n",
       " 8                  119294.0      119294   \n",
       " 9                  119299.0      119299   \n",
       " 10                 119301.0      119301   \n",
       " 11                 119324.0      119324   \n",
       " \n",
       "                                                text_y  \n",
       " 0   @105838 @AppleSupport Me too am suffering , ho...  \n",
       " 1   I just updated my phone and suddenly everythin...  \n",
       " 2   @AppleSupport after the 11.0.2 my phone just s...  \n",
       " 3   Okay @76099 I used my fucking phone for 2 minu...  \n",
       " 4   @AppleSupport Can you get my iPhone 7plus back...  \n",
       " 6   So the new @76099 update does not let me liste...  \n",
       " 8   Took my phone off charge at 7:20am.\\n\\n8:03am ...  \n",
       " 9   @AppleSupport I need a new code for my I-store...  \n",
       " 10  @76099 @AppleSupport fix this update. It’s hor...  \n",
       " 11  @AppleSupport I have the latest version iOS. I...  ,\n",
       "    tweet_id_x     author_id  inbound                      created_at  \\\n",
       " 3      119261  SpotifyCares    False  Wed Oct 11 14:41:35 +0000 2017   \n",
       " 7      119288  SpotifyCares    False  Thu Oct 12 12:09:13 +0000 2017   \n",
       " \n",
       "                                               text_x response_tweet_id  \\\n",
       " 3  You're welcome! If there's anything else we ca...               NaN   \n",
       " 7  Got it. Can you try the steps here for us: htt...               NaN   \n",
       " \n",
       "    in_response_to_tweet_id  tweet_id_y  \\\n",
       " 3                 119260.0      119260   \n",
       " 7                 119287.0      119287   \n",
       " \n",
       "                                               text_y  \n",
       " 3                   @SpotifyCares Brilliant thanks 😊  \n",
       " 7  @SpotifyCares It's on a Macbook Air (early 201...  ,\n",
       "    tweet_id_x author_id  inbound                      created_at  \\\n",
       " 5      119322     Tesco    False  Wed Oct 11 13:49:29 +0000 2017   \n",
       " 6      119335     Tesco    False  Wed Oct 11 15:38:07 +0000 2017   \n",
       " \n",
       "                                               text_x response_tweet_id  \\\n",
       " 5  Can you DM me your full name, address and emai...               NaN   \n",
       " 6  If that doesn't help please DM your full name,...               NaN   \n",
       " \n",
       "    in_response_to_tweet_id  tweet_id_y  \\\n",
       " 5                 119321.0      119321   \n",
       " 6                 119333.0      119333   \n",
       " \n",
       "                                               text_y  \n",
       " 5  @Tesco Done all that. Still telling me there a...  \n",
       " 6  @Tesco bit of both - finding the layout cumber...  ]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of tweets responded by 'AmazonHelp', 'AppleSupport', and 'Uber_Support'\n",
    "dataset=[]\n",
    "for i in clist:\n",
    "    dataset.append(pre(df,i))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a model for encoding: w2v, tfidf, lsi, or lda? lda\n",
      "Please wait for system to set up\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['text_y', 'text_x'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m time1\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    220\u001b[0m seg0 \u001b[38;5;241m=\u001b[39m Seg()\n\u001b[0;32m--> 221\u001b[0m List_kw0, questionList0, answerList0 \u001b[38;5;241m=\u001b[39m \u001b[43mread_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseg0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m ss0 \u001b[38;5;241m=\u001b[39m SentenceSimilarity(seg0,clist[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    223\u001b[0m ss0\u001b[38;5;241m.\u001b[39mset_sentences(questionList0)\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mread_corpus\u001b[0;34m(df, seg)\u001b[0m\n\u001b[1;32m      4\u001b[0m qList_kw \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m aList \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m data_ls \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m data_ls:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['text_y', 'text_x'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    way=input('Select a model for encoding: w2v, tfidf, lsi, or lda? ')\n",
    "    #Set up for specific model\n",
    "    w2v=False\n",
    "    if way == 'w2v':\n",
    "        w2v=True\n",
    "        print('Please wait for the system to set up.')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "        ss1.w2vModel()\n",
    "#         ss1.TfidfModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "        ss2.w2vModel()\n",
    "#         ss2.TfidfModel() \n",
    "        time2=time.time()\n",
    "        print('The setup is now complete, which took {} s.'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "        #Start chatting with customer\n",
    "        print('Hey there! This is Auto Customer Service. First, please choose the company you would like to chat with:')\n",
    "        while True:\n",
    "            company=input(\"0 for Amazon, 1 for Apple, 2 for Uber, 'q' to quit: \")\n",
    "            if company in ['0','1','2']:\n",
    "                while True:\n",
    "                    question = input(\"Please type your question here or press 'q' to quit: \")\n",
    "                    if question == 'q':\n",
    "                        break\n",
    "                    time1 = time.time()\n",
    "\n",
    "                    # chats for Amazon\n",
    "                    if company=='0':\n",
    "                        question_k = ss0.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer(s) from AmazonHelp:')\n",
    "                                print(answerList0[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is your problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to help.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database system, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in the system, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList0[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')# chats for apple\n",
    "                    elif company=='1':\n",
    "                        question_k = ss1.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer from AppleSupport')\n",
    "                                print(answerList1[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is this problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList1[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')\n",
    "\n",
    "                    # chats for Uber\n",
    "                    else:\n",
    "                        question_k = ss2.similarity_v(question, 5)\n",
    "                        time2 = time.time()\n",
    "                        for i in range(5):\n",
    "                            if question_k[1][i]>=0.5:\n",
    "                                print('Thanks for asking, here is the',i+1,'most likely answer(s) from Uber_Support')\n",
    "                                print(answerList2[question_k[0][i]])\n",
    "                                while True:\n",
    "                                    solved=input('Is this problem solved? (input y/n)')\n",
    "                                    if solved=='n' or solved=='y':\n",
    "                                        print()\n",
    "                                        break\n",
    "                                    elif solved!='y':\n",
    "                                        input('Please enter y/n')\n",
    "                                        continue\n",
    "                                if solved=='y':\n",
    "                                    print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                    break\n",
    "\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                                else:\n",
    "                                    print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                                break\n",
    "\n",
    "                        for idx, score in zip(*question_k):\n",
    "                            print(\"Similar questions： {},                score： {}\".format(questionList2[idx], score))\n",
    "\n",
    "                        cost = time2 - time1\n",
    "                        print('It took {} s to look for the answers'.format(cost))\n",
    "                        print('---------------------------------------------------------------------------------------------------')\n",
    "                        print('Is there anything else I can help?')\n",
    "                print('Thank you for asking. Would you like to ask questions about other companies?')\n",
    "                \n",
    "                    \n",
    "            elif company=='q':\n",
    "                print('Thank you. Say safe and have a good one!')\n",
    "                break\n",
    "            else:\n",
    "                print('Please input 0, 1, 2 or q')\n",
    "            \n",
    "        break\n",
    "            \n",
    "            \n",
    "        \n",
    "    elif way == 'tfidf':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "        ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.TfidfModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.TfidfModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "        \n",
    "    elif way == 'lsi':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(dataset[0],seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        ss0.LsiModel()\n",
    "        #     ss.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.LsiModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.LsiModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "        \n",
    "    elif way == 'lda':\n",
    "        print('Please wait for system to set up')\n",
    "        time1=time.time()\n",
    "        seg0 = Seg()\n",
    "        List_kw0, questionList0, answerList0 = read_corpus(df,seg0)\n",
    "        ss0 = SentenceSimilarity(seg0,clist[0])\n",
    "        ss0.set_sentences(questionList0)\n",
    "        #ss0.w2vModel()\n",
    "#         ss0.TfidfModel() \n",
    "        #     ss.LsiModel()\n",
    "        ss0.LdaModel()        \n",
    "        seg1 = Seg()\n",
    "        List_kw1, questionList1, answerList1 = read_corpus(dataset[1],seg1)\n",
    "        ss1 = SentenceSimilarity(seg1,clist[1])\n",
    "        ss1.set_sentences(questionList1)\n",
    "#         ss1.w2vModel()\n",
    "        ss1.LdaModel() \n",
    "        seg2 = Seg()\n",
    "        List_kw2, questionList2, answerList2 = read_corpus(dataset[2],seg2)\n",
    "        ss2 = SentenceSimilarity(seg2,clist[2])\n",
    "        ss2.set_sentences(questionList2)\n",
    "#         ss2.w2vModel\n",
    "        ss2.LdaModel() \n",
    "        time2=time.time()\n",
    "        print('Finished! Time cost for setting up: {} s'.format(time2-time1))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        break\n",
    "    else:\n",
    "        print('Please input right')\n",
    "        continue\n",
    "        \n",
    "if w2v==False:\n",
    "    print('Hey there! This is Auto Customer Service. First please choose the company:')\n",
    "    while True:\n",
    "        company=input('0 for Amazon, 1 for Apple, 2 for Uber: ')\n",
    "        if company in ['0','1','2']:\n",
    "            while True:        \n",
    "                question = input(\"Please type your question here ('q' to quit): \")\n",
    "                if question == 'q':\n",
    "                    break\n",
    "                time1 = time.time()\n",
    "                if company=='0':           \n",
    "                    question_k = ss0.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from AmazonHelp')\n",
    "                            print(answerList0[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break                    \n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList0[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('What else can I help')\n",
    "                elif company=='1':\n",
    "                    question_k = ss1.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from AppleSupport')\n",
    "                            print(answerList1[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in our database, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in our database, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList1[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('Is there anything else I can help?')\n",
    "                else:\n",
    "                    question_k = ss2.similarity_k(question, 5)\n",
    "                    time2 = time.time()\n",
    "                    for i in range(5):\n",
    "                        if question_k[1][i]>=0.5:\n",
    "                            print('Thanks for asking, here is the',i+1,'most likely answer(s) from Uber_Support')\n",
    "                            print(answerList2[question_k[0][i]])\n",
    "                            while True:\n",
    "                                solved=input('Is this problem solved? (input y/n)')\n",
    "                                if solved=='n' or solved=='y':\n",
    "                                    print()\n",
    "                                    break\n",
    "                                elif solved!='y':\n",
    "                                    input('Please enter y/n')\n",
    "                                    continue\n",
    "                            if solved=='y':\n",
    "                                print('Thank you for using Auto Customer Service. It\\'s my pleasure to solve your problem.')\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            if i == 0:\n",
    "                                print('Unfortunately, I can\\'t find any answer in the systen, please contact human services.' )\n",
    "                            else:\n",
    "                                print('Unfortunately, I can\\'t find more answers in the systen, please contact human services if you still have questions.')\n",
    "                            break\n",
    "\n",
    "\n",
    "                    for idx, score in zip(*question_k):\n",
    "                        print(\"Similar questions： {},                score： {}\".format(questionList2[idx], score))\n",
    "\n",
    "                    cost = time2 - time1\n",
    "                    print('It took {} s to look for the answers?'.format(cost))\n",
    "                    print('---------------------------------------------------------------------------------------------------')\n",
    "                    print('Is there anything else I can help')\n",
    "            \n",
    "            print('Thank you for asking. Do you want to ask questions about other companies?')\n",
    "                \n",
    "                    \n",
    "        elif company=='q':\n",
    "            print('Thank you. Stay safe and have a good one!')\n",
    "            break\n",
    "        else:\n",
    "            print('Please enter 0, 1, 2 or q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
